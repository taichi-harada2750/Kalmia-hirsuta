import cv2
import mediapipe as mp
from pythonosc import udp_client
import math

# --- è¨­å®š ---
camera_index = 1  # ä½¿ç”¨ã™ã‚‹ã‚«ãƒ¡ãƒ©ç•ªå·
OSC_IP = "127.0.0.1"
OSC_PORT = 9000

# --- MediaPipe Hands åˆæœŸåŒ– ---
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=2,  # ä¸¡æ‰‹å¯¾å¿œ
    min_detection_confidence=0.7,
    min_tracking_confidence=0.7)

client = udp_client.SimpleUDPClient(OSC_IP, OSC_PORT)

# --- ã‚«ãƒ¡ãƒ©æº–å‚™ ---
cap = cv2.VideoCapture(camera_index)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

if not cap.isOpened():
    raise RuntimeError(f"âŒ ã‚«ãƒ¡ãƒ© {camera_index} ã‚’é–‹ã‘ã¾ã›ã‚“ã€‚")

print(f"ğŸ¥ ã‚«ãƒ¡ãƒ© {camera_index} ã‚’ä½¿ç”¨ä¸­ã€‚'q'ã‚­ãƒ¼ã§çµ‚äº†ã—ã¾ã™ã€‚")

# --- æ´ã¿ãƒãƒ¼ã‚ºåˆ¤å®š ---
def is_grabbing_pose(landmarks):
    def folded(tip_id, pip_id):
        return landmarks[tip_id].y > landmarks[pip_id].y
    return (
        folded(8, 6) and
        folded(12, 10) and
        folded(16, 14) and
        folded(20, 18)
    )

# --- ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ— ---
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—å¤±æ•—")
        break

    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = hands.process(rgb_frame)
    output_frame = frame.copy()

    if results.multi_hand_landmarks and results.multi_handedness:
        for i, hand_landmarks in enumerate(results.multi_hand_landmarks):
            handedness = results.multi_handedness[i].classification[0].label  # 'Left' or 'Right'
            landmarks = hand_landmarks.landmark

            wrist = landmarks[0]
            middle_base = landmarks[9]
            palm_x = (wrist.x + middle_base.x) / 2
            palm_y = (wrist.y + middle_base.y) / 2
            grabbing = is_grabbing_pose(landmarks)

            # ã‚¢ãƒ‰ãƒ¬ã‚¹åˆ†å²
            address = "/hand/left_palm" if handedness == "Left" else "/hand/right_palm"
            client.send_message(address, [palm_x, palm_y, float(grabbing)])

            # å¯è¦–åŒ–
            h, w, _ = frame.shape
            cx, cy = int(palm_x * w), int(palm_y * h)
            color = (255, 0, 0) if handedness == "Left" else (0, 255, 255)
            if grabbing:
                color = (0, 255, 0)
            cv2.circle(output_frame, (cx, cy), 14, color, -1)

    cv2.imshow("MediaPipe Dual Hand Tracker", output_frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
